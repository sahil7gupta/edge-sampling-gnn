{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Edge Sampling on GNNs**\n",
        "### **CIS 700 - Machine Learning With Graphs**\n",
        "### **Sahil Gupta**\n"
      ],
      "metadata": {
        "id": "mzu_guUj10zY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialise the environment, import packages and enable training on GPU"
      ],
      "metadata": {
        "id": "EGb1PSLN2OEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "os.environ['PYTHONWARNINGS'] = \"ignore\"\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "Uw3SG7ZQCMLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download graph datasets to storage. In our case, we are using Cora, CiteSeer and PubMed datasets"
      ],
      "metadata": {
        "id": "WCFpNkPn2cgs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0jvM6bpBfjS",
        "outputId": "9447f1a6-a595-4298-8419-0e4ae5b1e539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: {'Cora': Cora(), 'CiteSeer': CiteSeer(), 'PubMed': PubMed()}:\n",
            "======================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "datasets={}\n",
        "datasets['Cora'] = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "datasets['CiteSeer'] = Planetoid(root='data/CiteSeer', name='CiteSeer', transform=NormalizeFeatures())\n",
        "datasets['PubMed'] = Planetoid(root='data/PubMed', name='PubMed', transform=NormalizeFeatures())\n",
        "\n",
        "print(f'Dataset: {datasets}:')\n",
        "print('======================')\n",
        "# print(f'Number of features: {datasets['Cora'].num_features}')\n",
        "# print(f'Number of classes: {datasets['Cora'].num_classes}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating 3 GNNs: GCN, GAT and TAGCN[3], and defining train and test functions"
      ],
      "metadata": {
        "id": "QWcrcVHw3dPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.nn import TAGConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, dataset):\n",
        "        super().__init__()\n",
        "        # torch.manual_seed(1234567)\n",
        "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, dataset):\n",
        "        heads = 8\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(dataset.num_features, hidden_channels, heads, dropout=0.6)\n",
        "        # On the Pubmed dataset, use `heads` output heads in `conv2`.\n",
        "        self.conv2 = GATConv(hidden_channels * heads, dataset.num_classes, heads=1,\n",
        "                             concat=False, dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class TAGCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, dataset):\n",
        "        super().__init__()\n",
        "        self.conv1 = TAGConv(dataset.num_features, hidden_channels)\n",
        "        self.conv2 = TAGConv(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "def train(data):\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      out = model(data.x, data.edge_index)\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      return loss\n",
        "\n",
        "def test(data):\n",
        "      model.eval()\n",
        "      out = model(data.x, data.edge_index)\n",
        "      pred = out.argmax(dim=1)\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
        "      return test_acc\n"
      ],
      "metadata": {
        "id": "DxOrawP8Csf6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifying experiment parameters and running experiments (Training + Testing)"
      ],
      "metadata": {
        "id": "r4fEn9ts6VoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import dropout_edge\n",
        "from torch_geometric.utils import dropout_path\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "# Experiment Parameters\n",
        "models = {\n",
        "    \"GCN\" : GCN,\n",
        "    \"GAT\" : GAT,\n",
        "    \"TAGCN\": TAGCN\n",
        "}\n",
        "sampling_ratio_range = np.arange (0.1, 1.1, 0.1)\n",
        "epoch_range = range(1, 101)\n",
        "sampling_methods = {\n",
        "    \"RE\" : dropout_edge,\n",
        "    \"RW\" : dropout_path\n",
        "}\n",
        "experiment_count = 5\n",
        "acc_values = [None]*experiment_count\n",
        "\n",
        "for i in range(experiment_count):\n",
        "  acc_values[i]={}\n",
        "  for modelKey in models:\n",
        "    acc_values[i][modelKey] = {}\n",
        "\n",
        "    for datasetKey in datasets:\n",
        "      dataset = datasets[datasetKey]\n",
        "      model = models[modelKey](hidden_channels=16, dataset = dataset).to(device)\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "      criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "      acc_values[i][modelKey][datasetKey] = {}\n",
        "\n",
        "\n",
        "      for sampling_method in sampling_methods:\n",
        "        acc_values[i][modelKey][datasetKey][sampling_method] = {}\n",
        "        acc_values[i][modelKey][datasetKey][sampling_method]['sampling_ratio'] = []\n",
        "        acc_values[i][modelKey][datasetKey][sampling_method]['test_acc'] = []\n",
        "        for sampling_ratio in sampling_ratio_range:\n",
        "          dataset = copy.deepcopy(datasets[datasetKey])\n",
        "\n",
        "\n",
        "          data = dataset[0].to(device)\n",
        "          # print (sampling_ratio)\n",
        "\n",
        "          totalEdges = data.edge_index.size(dim=1)\n",
        "          data.edge_index , data.edge_mask = sampling_methods[sampling_method](data.edge_index , p = 1-sampling_ratio)\n",
        "          true_sampling_ratio = float(data.edge_index.size(dim=1))/totalEdges\n",
        "          # print(data.edge_index.size(dim=1))\n",
        "          print(\n",
        "               \"Training + Testing: \" +\n",
        "               \"Experiment: \" + str(i) +\n",
        "               \", Model: \"  + modelKey +\n",
        "               \", Dataset: \"  + datasetKey +\n",
        "               \", Sampling Method: \" + sampling_method +\n",
        "               \", Sampling Ratio: \" + str(true_sampling_ratio)\n",
        "               )\n",
        "\n",
        "          for epoch in epoch_range:\n",
        "            loss = train(data)\n",
        "            # print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "          test_acc = test(data)\n",
        "          print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "          # print(true_sampling_ratio)\n",
        "          acc_values[i][modelKey][datasetKey][sampling_method]['sampling_ratio'].append(true_sampling_ratio)\n",
        "          acc_values[i][modelKey][datasetKey][sampling_method]['test_acc'].append(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLCA0FcuDvhV",
        "outputId": "95e985e2-71cd-49fc-8726-537073942138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 0.10145888594164457\n",
            "Test Accuracy: 0.5910\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 0.2044334975369458\n",
            "Test Accuracy: 0.6530\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 0.3006820765441455\n",
            "Test Accuracy: 0.6800\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 0.39759378552482\n",
            "Test Accuracy: 0.7170\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 0.5035998484274347\n",
            "Test Accuracy: 0.7440\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 0.5942591890867753\n",
            "Test Accuracy: 0.7720\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 0.7068965517241379\n",
            "Test Accuracy: 0.7730\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 0.8057029177718833\n",
            "Test Accuracy: 0.7900\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 0.8992042440318302\n",
            "Test Accuracy: 0.8030\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RE, Sampling Ratio: 1.0\n",
            "Test Accuracy: 0.8120\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 0.054281924971580145\n",
            "Test Accuracy: 0.6060\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 0.07900719969685487\n",
            "Test Accuracy: 0.6380\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 0.1178476695718075\n",
            "Test Accuracy: 0.6260\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 0.15071996968548693\n",
            "Test Accuracy: 0.6660\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 0.2125805229253505\n",
            "Test Accuracy: 0.6360\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 0.3006820765441455\n",
            "Test Accuracy: 0.7090\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 0.4140773020083365\n",
            "Test Accuracy: 0.7260\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 0.5532398635846911\n",
            "Test Accuracy: 0.7560\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 0.7382531261841606\n",
            "Test Accuracy: 0.7970\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: Cora, Sampling Method: RW, Sampling Ratio: 1.0\n",
            "Test Accuracy: 0.8180\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 0.1022627416520211\n",
            "Test Accuracy: 0.6150\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 0.19804481546572936\n",
            "Test Accuracy: 0.6200\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 0.2989894551845343\n",
            "Test Accuracy: 0.6750\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 0.40136203866432335\n",
            "Test Accuracy: 0.6490\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 0.5012082601054482\n",
            "Test Accuracy: 0.6630\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 0.5985281195079086\n",
            "Test Accuracy: 0.6810\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 0.7032073813708261\n",
            "Test Accuracy: 0.6660\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 0.7995386643233744\n",
            "Test Accuracy: 0.6850\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 0.8991652021089631\n",
            "Test Accuracy: 0.7100\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RE, Sampling Ratio: 1.0\n",
            "Test Accuracy: 0.7090\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 0.0531634446397188\n",
            "Test Accuracy: 0.6430\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 0.07227592267135326\n",
            "Test Accuracy: 0.6400\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 0.10830404217926186\n",
            "Test Accuracy: 0.6230\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 0.15432776801405976\n",
            "Test Accuracy: 0.6140\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 0.218804920913884\n",
            "Test Accuracy: 0.6310\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 0.3084358523725835\n",
            "Test Accuracy: 0.6510\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 0.42629613356766255\n",
            "Test Accuracy: 0.6720\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 0.5583260105448155\n",
            "Test Accuracy: 0.6730\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 0.7447275922671354\n",
            "Test Accuracy: 0.6880\n",
            "Training + Testing: Experiment: 0, Model: GCN, Dataset: CiteSeer, Sampling Method: RW, Sampling Ratio: 1.0\n",
            "Test Accuracy: 0.7090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting results: Comparing Different edge sampling methods - Percentage drop in test accuracy"
      ],
      "metadata": {
        "id": "Rz0dKyQu60IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "legend = {\n",
        "    \"RE\" : {'color':'r', 'label':'Random Edge'},\n",
        "    \"RW\" : {'color':'b', 'label':'Random Walk'},\n",
        "}\n",
        "\n",
        "# print (acc_values)\n",
        "\n",
        "fig = plt.figure(constrained_layout=True, figsize=(13,13))\n",
        "\n",
        "subfigs = fig.subfigures(len(acc_values[0]), 1)\n",
        "\n",
        "for subfig, modelKey in zip(subfigs,acc_values[0]):\n",
        "\n",
        "    subfig.suptitle(modelKey)\n",
        "    axs = subfig.subplots(1, len(acc_values[0][modelKey]))\n",
        "    for a,datasetKey in zip(axs,acc_values[0][modelKey].keys()):\n",
        "      for sampling_method in acc_values[0][modelKey][datasetKey]:\n",
        "\n",
        "        y_values=[]\n",
        "        for i in range(experiment_count):\n",
        "          curr_exp_acc = acc_values[i][modelKey][datasetKey][sampling_method]['test_acc']\n",
        "          max_accuracy = curr_exp_acc[len(curr_exp_acc)-1]\n",
        "          curr_exp_acc = [(max_accuracy - k)*100/max_accuracy for k in curr_exp_acc]\n",
        "          y_values.append(np.array(curr_exp_acc))\n",
        "\n",
        "        y = [np.mean(k) for k in zip(*y_values)]\n",
        "        # print(y)\n",
        "        yerr = [np.std(k) for k in zip(*y_values)]\n",
        "        # print(yerr)\n",
        "\n",
        "        x = acc_values[i][modelKey][datasetKey][sampling_method]['sampling_ratio']\n",
        "        a.errorbar(x,y,yerr = yerr, color = legend[sampling_method]['color'], label = legend[sampling_method]['label'])\n",
        "\n",
        "        a.legend()\n",
        "        a.set(xlabel=\"Edge Sampling Ratio\", ylabel=\"Percentage drop in test accuracy\")\n",
        "        a.set_title(datasetKey)\n",
        "        # a.set_xticks(np.arange(min(x)-0.1, max(x)+0.1, 0.10))\n",
        "        # a.set_yticks(np.arange(0, max(y)+0.01, 0.02))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jv8rtjrPrdPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting results: Comparing Different edge sampling methods - Absolute test accuracy"
      ],
      "metadata": {
        "id": "o-HJ55QV7V-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "legend = {\n",
        "    \"RE\" : {'color':'r', 'label':'Random Edge'},\n",
        "    \"RW\" : {'color':'b', 'label':'Random Walk'},\n",
        "}\n",
        "\n",
        "# print (acc_values)\n",
        "\n",
        "fig = plt.figure(constrained_layout=True, figsize=(13,13))\n",
        "\n",
        "subfigs = fig.subfigures(len(acc_values[0]), 1)\n",
        "\n",
        "for subfig, modelKey in zip(subfigs,acc_values[0]):\n",
        "\n",
        "    subfig.suptitle(modelKey)\n",
        "    axs = subfig.subplots(1, len(acc_values[0][modelKey]))\n",
        "    for a,datasetKey in zip(axs,acc_values[0][modelKey].keys()):\n",
        "      for sampling_method in acc_values[0][modelKey][datasetKey]:\n",
        "\n",
        "        y_values=[]\n",
        "        for i in range(experiment_count):\n",
        "          curr_exp_acc = acc_values[i][modelKey][datasetKey][sampling_method]['test_acc']\n",
        "          y_values.append(np.array(curr_exp_acc))\n",
        "\n",
        "\n",
        "        y = [np.mean(k) for k in zip(*y_values)]\n",
        "        # print(y)\n",
        "        yerr = [np.std(k) for k in zip(*y_values)]\n",
        "        # print(yerr)\n",
        "        x = acc_values[i][modelKey][datasetKey][sampling_method]['sampling_ratio']\n",
        "        a.errorbar(x,y,yerr = yerr, color = legend[sampling_method]['color'], label = legend[sampling_method]['label'])\n",
        "\n",
        "        a.legend()\n",
        "        a.set(xlabel=\"Edge Sampling Ratio\", ylabel=\"Test Accuracy\")\n",
        "        a.set_title(datasetKey)\n",
        "        # a.set_xticks(np.arange(min(x)-0.1, max(x)+0.1, 0.10))\n",
        "        # a.set_yticks(np.arange(0, max(y)+0.01, 0.02))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C2X_AjhL7VeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting results: Comparing Different edge sampling methods - Comparing accuracies of various GNNs"
      ],
      "metadata": {
        "id": "FPOsJ7sEnG-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "legend_models = {\n",
        "    \"GCN\" : {'color':'r', 'label':'GCN'},\n",
        "    \"GAT\" : {'color':'b', 'label':'GAT'},\n",
        "    \"TAGCN\" : {'color':'g', 'label':'TAGCN'},\n",
        "}\n",
        "\n",
        "fig = plt.figure(constrained_layout=True, figsize=(13,13))\n",
        "\n",
        "subfigs = fig.subfigures(len(acc_values[0]), 1)\n",
        "\n",
        "# print(list(acc_values[0].keys())[0])\n",
        "for subfig, datasetKey in zip(subfigs,acc_values[0][list(acc_values[0].keys())[0]]):\n",
        "\n",
        "    subfig.suptitle(datasetKey)\n",
        "    axs = subfig.subplots(1, len(acc_values[0][list(acc_values[0].keys())[0]][datasetKey]))\n",
        "    # print(acc_values[0][list(acc_values[0].keys())[0]][datasetKey])\n",
        "    for a,sampling_method in zip(axs,acc_values[0][list(acc_values[0].keys())[0]][datasetKey]):\n",
        "      for modelKey in acc_values[0].keys():\n",
        "\n",
        "        y_values=[]\n",
        "        for i in range(experiment_count):\n",
        "          curr_exp_acc = acc_values[i][modelKey][datasetKey][sampling_method]['test_acc']\n",
        "          y_values.append(np.array(curr_exp_acc))\n",
        "\n",
        "        # print(\"y_values\")\n",
        "        # print(y_values)\n",
        "        y = [np.mean(k) for k in zip(*y_values)]\n",
        "        # print(y)\n",
        "        yerr = [np.std(k) for k in zip(*y_values)]\n",
        "        x = acc_values[i][modelKey][datasetKey][sampling_method]['sampling_ratio']\n",
        "        a.errorbar(x,y,yerr = yerr, color = legend_models[modelKey]['color'], label = legend_models[modelKey]['label'])\n",
        "\n",
        "        a.legend()\n",
        "        a.set(xlabel=\"Edge Sampling Ratio\", ylabel=\"Test Accuracy\")\n",
        "        a.set_title(legend[sampling_method]['label'])\n",
        "        # a.set_xticks(np.arange(min(x)-0.1, max(x)+0.1, 0.10))\n",
        "        # a.set_yticks(np.arange(0, max(y)+0.01, 0.02))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WatuqqpJq14W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "1. Initial code taken from: https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial\n",
        "\n",
        "2. Jure Leskovec and Christos Faloutsos. 2006. Sampling from large graphs. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '06). Association for Computing Machinery, New York, NY, USA, 631–636. https://doi.org/10.1145/1150402.1150479\n",
        "\n",
        "3. Jian Du, Shanghang Zhang, Guanhang Wu, José M. F. Moura, & Soummya Kar. (2018). Topology Adaptive Graph Convolutional Networks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "grHemfIIucR6"
      }
    }
  ]
}